{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all of the things you need to import!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 14 (or so): TF-IDF text analysis and clustering\n",
    "\n",
    "Hooray, we kind of figured out how text analysis works! Some of it is still magic, but at least the **TF** and **IDF** parts make a little sense. Kind of. Somewhat.\n",
    "\n",
    "No, just kidding, we're *professionals* now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Congressional Record\n",
    "\n",
    "The [Congressional Record](https://en.wikipedia.org/wiki/Congressional_Record) is more or less what happened in Congress every single day. Speeches and all that. A good large source of text data, maybe?\n",
    "\n",
    "Let's pretend it's totally secret but we just got it leaked to us in a data dump, and we need to check it out. It was leaked from [this page here](http://www.cs.cornell.edu/home/llee/data/convote.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9607k  100 9607k    0     0  5201k      0  0:00:01  0:00:01 --:--:-- 5201k\n"
     ]
    }
   ],
   "source": [
    "# If you'd like to download it through the command line...\n",
    "!curl -O http://www.cs.cornell.edu/home/llee/data/convote/convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And then extract it through the command line...\n",
    "!tar -zxf convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can explore the files if you'd like, but we're going to get the ones from `convote_v1.1/data_stage_one/development_set/`. It's a bunch of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convote_v1.1/data_stage_one/development_set/052_400011_0327014_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327025_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327044_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327046_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_1479036_DON.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob finds files matching a certain filename pattern\n",
    "import glob\n",
    "\n",
    "# Give me all the text files\n",
    "paths = glob.glob('convote_v1.1/data_stage_one/development_set/*')\n",
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So great, we have 702 of them. Now let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr. chairman , i thank the gentlewoman for yie...</td>\n",
       "      <td>052_400011_0327014_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr. chairman , i want to thank my good friend ...</td>\n",
       "      <td>052_400011_0327025_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr. chairman , i rise to make two fundamental ...</td>\n",
       "      <td>052_400011_0327044_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr. chairman , reclaiming my time , let me mak...</td>\n",
       "      <td>052_400011_0327046_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr. chairman , i thank my distinguished collea...</td>\n",
       "      <td>052_400011_1479036_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  mr. chairman , i thank the gentlewoman for yie...   \n",
       "1  mr. chairman , i want to thank my good friend ...   \n",
       "2  mr. chairman , i rise to make two fundamental ...   \n",
       "3  mr. chairman , reclaiming my time , let me mak...   \n",
       "4  mr. chairman , i thank my distinguished collea...   \n",
       "\n",
       "                     filename  \\\n",
       "0  052_400011_0327014_DON.txt   \n",
       "1  052_400011_0327025_DON.txt   \n",
       "2  052_400011_0327044_DON.txt   \n",
       "3  052_400011_0327046_DON.txt   \n",
       "4  052_400011_1479036_DON.txt   \n",
       "\n",
       "                                            pathname  \n",
       "0  convote_v1.1/data_stage_one/development_set/05...  \n",
       "1  convote_v1.1/data_stage_one/development_set/05...  \n",
       "2  convote_v1.1/data_stage_one/development_set/05...  \n",
       "3  convote_v1.1/data_stage_one/development_set/05...  \n",
       "4  convote_v1.1/data_stage_one/development_set/05...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = []\n",
    "for path in paths:\n",
    "    with open(path) as speech_file:\n",
    "        speech = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': speech_file.read()\n",
    "        }\n",
    "    speeches.append(speech)\n",
    "speeches_df = pd.DataFrame(speeches)\n",
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we had the `texts` variable. For the homework can just do `speeches_df['content']` to get the same sort of list of stuff.\n",
    "\n",
    "**Take a look at the contents of the first 5 speeches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. chairman , i thank the gentlewoman for yielding me this time . \n",
      "my good colleague from california raised the exact and critical point .  \n",
      "\n",
      "mr. chairman , i want to thank my good friend from california ( mr. rohrabacher ) xz4003430 . \n",
      "i will always remember that day , as we all w \n",
      "\n",
      "mr. chairman , i rise to make two fundamental points before we proceed to vote on this . \n",
      "the two points are these : this resolution does no \n",
      "\n",
      "mr. chairman , reclaiming my time , let me make two final points : one , the majority party must understand this : if you are at a republica \n",
      "\n",
      "mr. chairman , i thank my distinguished colleague , and i appreciate his leadership on this issue . \n",
      "the gentleman from california ( mr. roh \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in speeches_df['content'][:5]:\n",
    "    print(item[:140], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing our analysis\n",
    "\n",
    "Use the `sklearn` package and a plain boring `CountVectorizer` to get a list of all of the tokens used in the speeches. If it won't list them all, that's ok! Make a dataframe with those terms as columns.\n",
    "\n",
    "**Be sure to include English-language stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<702x9106 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 56106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "X = count_vectorizer.fit_transform(speeches_df['content'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00007</th>\n",
       "      <th>018</th>\n",
       "      <th>050</th>\n",
       "      <th>092</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>108th</th>\n",
       "      <th>109th</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>yields</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroing</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zigler</th>\n",
       "      <th>zirkin</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoellick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 9106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  00007  018  050  092  10  100  106  107  108  108th  109th  10th  11  \\\n",
       "0    0      0    0    0    0   0    0    0    0    0      0      0     0   1   \n",
       "1    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "2    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "3    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "4    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "5    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "6    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "7    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "8    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "9    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "\n",
       "   110    ...     yields  york  yorkers  young  younger  youngsters  youth  \\\n",
       "0    0    ...          0     0        0      0        0           0      0   \n",
       "1    0    ...          0     0        0      0        0           0      0   \n",
       "2    0    ...          0     0        0      0        0           0      0   \n",
       "3    0    ...          0     0        0      0        0           0      0   \n",
       "4    0    ...          0     0        0      0        0           0      0   \n",
       "5    0    ...          0     0        0      0        0           0      0   \n",
       "6    0    ...          0     0        0      0        0           0      0   \n",
       "7    0    ...          0     0        0      0        0           0      0   \n",
       "8    0    ...          0     0        0      0        0           0      0   \n",
       "9    0    ...          0     0        0      0        0           0      0   \n",
       "\n",
       "   yuan  zero  zeroing  zeros  zigler  zirkin  zoe  zoellick  \n",
       "0     0     0        0      0       0       0    0         0  \n",
       "1     0     0        0      0       0       0    0         0  \n",
       "2     0     0        0      0       0       0    0         0  \n",
       "3     0     0        0      0       0       0    0         0  \n",
       "4     0     0        0      0       0       0    0         0  \n",
       "5     0     0        0      0       0       0    0         0  \n",
       "6     0     0        0      0       0       0    0         0  \n",
       "7     0     0        0      0       0       0    0         0  \n",
       "8     0     0        0      0       0       0    0         0  \n",
       "9     0     0        0      0       0       0    0         0  \n",
       "\n",
       "[10 rows x 9106 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's **far** too big to even look at. Let's try to get a list of features from a new `CountVectorizer` that only takes the top 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<702x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11088 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "X = count_vectorizer.fit_transform(speeches_df['content'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>11</th>\n",
       "      <th>act</th>\n",
       "      <th>allow</th>\n",
       "      <th>amendment</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>amp</th>\n",
       "      <th>association</th>\n",
       "      <th>balance</th>\n",
       "      <th>based</th>\n",
       "      <th>believe</th>\n",
       "      <th>bipartisan</th>\n",
       "      <th>chairman</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>teachers</th>\n",
       "      <th>thank</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>trade</th>\n",
       "      <th>united</th>\n",
       "      <th>urge</th>\n",
       "      <th>vote</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  11  act  allow  amendment  america  american  amp  association  \\\n",
       "0    0   1    3      0          0        0         3    0            0   \n",
       "1    0   0    1      1          1        0         0    0            0   \n",
       "2    0   0    0      0          0        0         1    0            0   \n",
       "3    0   0    0      0          0        1         0    0            0   \n",
       "4    0   0    0      0          1        0         0    0            0   \n",
       "\n",
       "   balance  based  believe  bipartisan  chairman  children  ...    teachers  \\\n",
       "0        0      0        1           0         3         0  ...           0   \n",
       "1        1      0        0           0         2         0  ...           0   \n",
       "2        0      0        0           0         2         0  ...           0   \n",
       "3        1      0        0           0         2         0  ...           0   \n",
       "4        0      0        0           0         1         0  ...           0   \n",
       "\n",
       "   thank  think  time  today  trade  united  urge  vote  want  way  work  \\\n",
       "0      1      3     3      2      0       1     0     0     1    1     0   \n",
       "1      1      0     2      2      0       0     0     1     1    3     0   \n",
       "2      0      0     0      0      0       0     0     1     0    0     0   \n",
       "3      0      0     2      0      0       1     0     1     1    1     0   \n",
       "4      1      0     1      0      0       0     0     2     0    0     0   \n",
       "\n",
       "   year  years  yield  \n",
       "0     0      0      1  \n",
       "1     1      0      0  \n",
       "2     0      0      1  \n",
       "3     0      0      0  \n",
       "4     0      0      2  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's push all of that into a dataframe with nicely named columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone seems to start their speeches with \"mr chairman\" - how many speeches are there total, and many don't mention \"chairman\" and how many mention neither \"mr\" nor \"chairman\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a total of 702 speeches, 250 don't mention “chairman” and 76 mention neither “mr” nor “chairman”.\n"
     ]
    }
   ],
   "source": [
    "no_chairman = X_df[X_df['chairman'] == 0]['chairman'].count()\n",
    "no_chairman_no_mr = X_df[(X_df['chairman'] == 0) & (X_df['mr'] == 0)]['chairman'].count()\n",
    "print(\"In a total of\", len(X_df), \"speeches,\", no_chairman, \"don't mention “chairman” and\", no_chairman_no_mr, \"mention neither “mr” nor “chairman”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the index of the speech thank is the most thankful, a.k.a. includes the word 'thank' the most times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of this speech is 577\n"
     ]
    }
   ],
   "source": [
    "print(\"The index of this speech is\", X_df['thank'].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I'm searching for `China` and `trade`, what are the top 3 speeches to read according to the `CountVectoriser`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These three speeches have the indexes  379 399 345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>china</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     china  trade\n",
       "379     29     63\n",
       "399     27      9\n",
       "345     16     11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_trade = X_df.sort_values(by=['china', 'trade'], ascending=[0, 0])[['china', 'trade']].head(3)\n",
    "print(\"These three speeches have the indexes \", *list(china_trade.index))\n",
    "china_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if I'm using a `TfidfVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  345 340 315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>china</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.078818</td>\n",
       "      <td>0.054187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.008197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        china     trade\n",
       "345  0.078818  0.054187\n",
       "340  0.057377  0.008197\n",
       "315  0.055000  0.035000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    return words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=simple_tokenizer, use_idf=False, norm='l1')\n",
    "X = tfidf_vectorizer.fit_transform(speeches_df['content'])\n",
    "TF_pd = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "china_trade = TF_pd.sort_values(by=['china', 'trade'], ascending=[0, 0])[['china', 'trade']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(china_trade.index))\n",
    "china_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the content of the speeches?** Here's a way to get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convote_v1.1/data_stage_one/development_set/052_400011_0327014_DON.txt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 0 is the first speech, which was the first one imported.\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. chairman , i thank the gentlewoman for yielding me this time . \r\n",
      "my good colleague from california raised the exact and critical point . \r\n",
      "the question is , what happens during those 45 days ? \r\n",
      "we will need to support elections . \r\n",
      "there is not a single member of this house who has not supported some form of general election , a special election , to replace the members at some point . \r\n",
      "but during that 45 days , what happens ? \r\n",
      "the chair of the constitution subcommittee says this is what happens : martial law . \r\n",
      "we do not know who would fill the vacancy of the presidency , but we do know that the succession act most likely suggests it would be an unelected person . \r\n",
      "the sponsors of the bill before us today insist , and i think rightfully so , on the importance of elections . \r\n",
      "but to then say that during a 45-day period we would have none of the checks and balances so fundamental to our constitution , none of the separation of powers , and that the presidency would be filled by an unelected member of the cabinet who not a single member of this country , not a single citizen , voted to fill that position , and that that person would have no checks and balances from congress for a period of 45 days i find extraordinary . \r\n",
      "i find it inconsistent . \r\n",
      "i find it illogical , and , frankly , i find it dangerous . \r\n",
      "the gentleman from wisconsin refused earlier to yield time , but i was going to ask him , if virginia has those elections in a shorter time period , they should be commended for that . \r\n",
      "so now we have a situation in the congress where the virginia delegation has sent their members here , but many other states do not have members here . \r\n",
      "do they at that point elect a speaker of the house in the absence of other members ? \r\n",
      "and then three more states elect their representatives , temporary replacements , or full replacements at that point . \r\n",
      "they come in . \r\n",
      "do they elect a new speaker ? \r\n",
      "and if that happens , who becomes the president under the succession act ? \r\n",
      "this bill does not address that question . \r\n",
      "this bill responds to real threats with fantasies . \r\n",
      "it responds with the fantasy , first of all , that a lot of people will still survive ; but we have no guarantee of that . \r\n",
      "it responds with the fantasy that those who do survive will do the right thing . \r\n",
      "we are here having this debate , we have debates every day , because people differ on what the right thing is to do . \r\n",
      "i have been in very traumatic situations with people in severe car wrecks and mountain climbing accidents . \r\n",
      "my experience has not been that crisis imbues universal sagacity and fairness . \r\n",
      "it has not been that . \r\n",
      "people respond in extraordinary ways , and we must preserve an institution that has the deliberative body and the checks and balances to meet those challenges . \r\n",
      "many of our states are going increasingly to mail-in ballots . \r\n",
      "we in this body were effectively disabled by an anthrax attack not long after september 11 . \r\n",
      "i would ask my dear friends , will you conduct this election in 45 days if there is anthrax in the mail and still preserve the franchise of the american people ? \r\n",
      "how will you do that ? \r\n",
      "you have no answer to that question . \r\n",
      "i find it extraordinary , frankly , that while saying you do not want to amend the constitution , we began this very congress by amending the constitution through the rule , by undermining the principle that a quorum is 50 percent of the body and instead saying it is however many people survive . \r\n",
      "and if that rule applies , who will designate it , who will implement it ? \r\n",
      "the speaker , or the speaker 's designee ? \r\n",
      "again , not an elected person , as you say is so critical and i believe is critical , but a temporary appointee , frankly , who not a single other member of this body knows who they are . \r\n",
      "so we not only have an unelected person , we have an unknown person who will convene this body , and who , by the way , could conceivably convene it for their own election to then become the president of the united states under the succession act . \r\n",
      "you have refused steadfastly to debate this real issue broadly . \r\n",
      "you had a mock debate in the committee on the judiciary in which the distinguished chairman presented my bill without allowing me the courtesy or dignity to defend it myself . \r\n",
      "and on that , you proudly say you defend democracy . \r\n",
      "sir , i think you dissemble in that regard . \r\n",
      "here is the fundamental question for us , my friends , and it is this : the american people are watching television and an announcement comes on and says the congress has been destroyed in a nuclear attack , the president and vice president are killed and the supreme court is dead and thousands of our citizens in this town are . \r\n",
      "what happens next ? \r\n",
      "under your bill , 45 days of chaos . \r\n",
      "apparently , according to the committee on the judiciary subcommittee on the constitution chairman , 45 days of marshal law , rule of this country by an unelected president with no checks and balances . \r\n",
      "or an alternative , an alternative which says quite simply that the people have entrusted the representatives they send here to make profound decisions , war , taxation , a host of other things , and those representatives would have the power under the bill of the gentleman from california ( mr. rohrabacher ) xz4003430 bill or mine to designate temporary successors , temporary , only until we can have a real election . \r\n",
      "the american people , in one scenario , are told we do not know who is going to run the country , we have no representatives ; where in another you will have temporary representatives carrying your interests to this great body while we deliberate and have real elections . \r\n",
      "that is the choice . \r\n",
      "you are making the wrong choice today if you think you have solved this problem . \r\n"
     ]
    }
   ],
   "source": [
    "# Pass that into 'cat' using { } which lets you put variables in shell commands\n",
    "# that way you can pass the path to cat\n",
    "!cat {paths[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now search for something else!** Another two terms that might show up. `elections` and `chaos`? Whatever you thnik might be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '--',\n",
       " '-central',\n",
       " '-china',\n",
       " '-women',\n",
       " 'aaron',\n",
       " 'aba',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abcs',\n",
       " 'abet',\n",
       " 'abhorrent',\n",
       " 'abide',\n",
       " 'abides',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abolish',\n",
       " 'abraham',\n",
       " 'abridgement',\n",
       " 'abroad',\n",
       " 'abrogation',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absolutely',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absurd',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'academic',\n",
       " 'academically',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'accede',\n",
       " 'accelerated',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accidents',\n",
       " 'acclaimed',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodating',\n",
       " 'accompanies',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusations',\n",
       " 'accused',\n",
       " 'accustom',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieving',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'aclu',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acronym',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ada',\n",
       " 'adamantly',\n",
       " 'adams',\n",
       " 'adc',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhere',\n",
       " 'adherents',\n",
       " 'adhering',\n",
       " 'adjacent',\n",
       " 'adjourn',\n",
       " 'adjournment',\n",
       " 'adjudicated',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admirable',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantaged',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advisor',\n",
       " 'advisories',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'aesthetic',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affects',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affirm',\n",
       " 'affirmative',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'affirms',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'affront',\n",
       " 'afghanistan',\n",
       " 'afl-cio',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african-american',\n",
       " 'afscme',\n",
       " 'aftermarket',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressively',\n",
       " 'aggrieved',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahs',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiding',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aims',\n",
       " 'air',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airplanes',\n",
       " 'aisle',\n",
       " 'ak',\n",
       " 'akin',\n",
       " 'akron',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarming',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'albany',\n",
       " 'alcee',\n",
       " 'aldebron',\n",
       " 'alerted',\n",
       " 'alexander',\n",
       " 'alexandria',\n",
       " 'alfred',\n",
       " 'alice',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligns',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all-time',\n",
       " 'allegations',\n",
       " 'allege',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'alleging',\n",
       " 'alleviate',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'allocate',\n",
       " 'allocation',\n",
       " 'allocations',\n",
       " 'allotment',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluded',\n",
       " 'almonds',\n",
       " 'alphabet',\n",
       " 'altamonte',\n",
       " 'alter',\n",
       " 'altered',\n",
       " 'alternate',\n",
       " 'alternates',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'alto',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'ambassador',\n",
       " 'ambulances',\n",
       " 'ameliorate',\n",
       " 'amend',\n",
       " 'amendable',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amendment',\n",
       " 'amendments',\n",
       " 'america',\n",
       " 'american',\n",
       " 'american-arab',\n",
       " 'americans',\n",
       " 'amos',\n",
       " 'amounting',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'amt',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analyze',\n",
       " 'anathema',\n",
       " 'anderson',\n",
       " 'andrea',\n",
       " 'andrews',\n",
       " 'anecdotes',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anguish',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annie',\n",
       " 'annihilation',\n",
       " 'anniston',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anonymous',\n",
       " 'ansje',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'antagonizing',\n",
       " 'antelope',\n",
       " 'anthony',\n",
       " 'anthrax',\n",
       " 'anti-american',\n",
       " 'anti-china',\n",
       " 'anti-civil',\n",
       " 'anti-defamation',\n",
       " 'anti-discrimination',\n",
       " 'anti-dumping',\n",
       " 'anti-forum',\n",
       " 'anti-lawsuit',\n",
       " 'anti-lawyer',\n",
       " 'anti-poverty',\n",
       " 'anti-sewage',\n",
       " 'anti-terrorism',\n",
       " 'anti-worker',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipates',\n",
       " 'antidumping',\n",
       " 'antietam',\n",
       " 'antiforum-shopping',\n",
       " 'antimiscegenation',\n",
       " 'antipathy',\n",
       " 'antiquated',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyplace',\n",
       " 'anytime',\n",
       " 'aoc',\n",
       " 'apa',\n",
       " 'apart',\n",
       " 'apathy',\n",
       " 'apologize',\n",
       " 'apostle',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appendices',\n",
       " 'applaud',\n",
       " 'appliance',\n",
       " 'applicability',\n",
       " 'applicable',\n",
       " 'applicants',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointee',\n",
       " 'appointing',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appreciably',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'appropriately',\n",
       " 'appropriates',\n",
       " 'appropriation',\n",
       " 'appropriations',\n",
       " 'appropriators',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approving',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'aptly',\n",
       " 'aquatic',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'architect',\n",
       " 'architects',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'ardently',\n",
       " 'ardmore',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'arena',\n",
       " 'argentina',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'argumentative',\n",
       " 'arguments',\n",
       " 'arid',\n",
       " 'arise',\n",
       " 'arisen',\n",
       " 'arising',\n",
       " 'aristocracies',\n",
       " 'aristocracy',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'armed',\n",
       " 'armies',\n",
       " 'armor',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arnold',\n",
       " 'arnolds',\n",
       " 'arrange',\n",
       " 'arrangements',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'arrested',\n",
       " 'arrests',\n",
       " 'arrival',\n",
       " 'arrived',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arsenal',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'articulate',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'arts',\n",
       " 'ascertain',\n",
       " 'asfe',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asides',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'asphyxiating',\n",
       " 'assault',\n",
       " 'assemble',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'asserted',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'assets',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assigns',\n",
       " 'assimilating',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisted',\n",
       " 'assisting',\n",
       " 'assists',\n",
       " 'assoc',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associates',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assumptions',\n",
       " 'assurance',\n",
       " 'assurances',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'assures',\n",
       " 'assuring',\n",
       " 'asthma',\n",
       " 'astounding',\n",
       " 'astronaut',\n",
       " 'astronomical',\n",
       " 'at-risk',\n",
       " 'athletic',\n",
       " 'atkins',\n",
       " 'atla',\n",
       " 'atlanta',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attaching',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacks',\n",
       " 'attain',\n",
       " 'attainable',\n",
       " 'attaining',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attest',\n",
       " 'attitude',\n",
       " 'attorney',\n",
       " 'attorneys',\n",
       " 'attract',\n",
       " 'audit',\n",
       " 'audited',\n",
       " 'auditing',\n",
       " 'audits',\n",
       " 'august',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorization',\n",
       " 'authorizations',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'authorizes',\n",
       " 'authorizing',\n",
       " 'authors',\n",
       " 'auto',\n",
       " 'autocratic',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'automobile',\n",
       " 'automotive',\n",
       " 'autonomy',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'aviation',\n",
       " 'avoid',\n",
       " 'avoidance',\n",
       " 'avoids',\n",
       " 'avowed',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'aware',\n",
       " 'awash',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'aye',\n",
       " 'ayes',\n",
       " 'az',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'baccalaureate',\n",
       " 'bachelor',\n",
       " 'backbone',\n",
       " 'backdrop',\n",
       " 'backed',\n",
       " 'backed-up',\n",
       " 'background',\n",
       " 'backgrounds',\n",
       " 'backlog',\n",
       " 'backlogs',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'backyards',\n",
       " 'bacteria',\n",
       " 'bacterial',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'baird',\n",
       " 'bait',\n",
       " 'bakers',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balances',\n",
       " 'balancing',\n",
       " 'bald',\n",
       " 'baldwin',\n",
       " 'balked',\n",
       " 'ball',\n",
       " 'ballooned',\n",
       " 'ballooning',\n",
       " 'ballot',\n",
       " 'ballots',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bane',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'bans',\n",
       " 'baptist',\n",
       " 'baptists',\n",
       " 'baptized',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barbarian',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'bargaining',\n",
       " 'bark',\n",
       " 'barn',\n",
       " 'barrage',\n",
       " 'barred',\n",
       " 'barrett',\n",
       " 'barrier',\n",
       " 'barriers',\n",
       " 'barring',\n",
       " 'barron',\n",
       " 'barrow',\n",
       " 'barry',\n",
       " 'bars',\n",
       " 'bartered',\n",
       " 'bartlett',\n",
       " 'base',\n",
       " 'based',\n",
       " 'based-sponsored',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basing',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'bass',\n",
       " 'batchelder',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'bay',\n",
       " 'bays',\n",
       " 'beach',\n",
       " 'beaches',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'bearing',\n",
       " 'bears',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'bees',\n",
       " 'beet',\n",
       " 'beets',\n",
       " 'befitting',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'beginnings',\n",
       " 'begins',\n",
       " 'begrudge',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behaving',\n",
       " 'behavior',\n",
       " 'behavioral',\n",
       " 'beijing',\n",
       " 'beings',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believer',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'bellevue',\n",
       " 'bellmore',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'below-market',\n",
       " 'beltway',\n",
       " 'belvoir',\n",
       " 'bench',\n",
       " 'benedict',\n",
       " 'beneficial',\n",
       " 'beneficiaries',\n",
       " 'benefit',\n",
       " 'benefited',\n",
       " 'benefiting',\n",
       " 'benefits',\n",
       " 'bequeath',\n",
       " 'berea',\n",
       " 'berman',\n",
       " 'bernice',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beth',\n",
       " 'bethany',\n",
       " 'bethesda',\n",
       " 'betrayal',\n",
       " 'betrays',\n",
       " 'better',\n",
       " 'betterment',\n",
       " 'beverly',\n",
       " 'bi-partisan',\n",
       " 'bicameral',\n",
       " 'bicentennial',\n",
       " 'bickering',\n",
       " 'bicycles',\n",
       " 'bid',\n",
       " 'bids',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggert',\n",
       " 'biggert-van',\n",
       " 'biggest',\n",
       " 'bigoted',\n",
       " 'bigotry',\n",
       " 'bike',\n",
       " 'bikes',\n",
       " 'bilateral',\n",
       " 'billion',\n",
       " 'billion-plus',\n",
       " 'billions',\n",
       " 'bills',\n",
       " 'bind',\n",
       " 'binding',\n",
       " 'biological',\n",
       " 'bioterrorism',\n",
       " 'bipartisan',\n",
       " 'bipartisanship',\n",
       " 'birth',\n",
       " 'birthplace',\n",
       " 'bisexual',\n",
       " 'bishop',\n",
       " 'bishops',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blackboard',\n",
       " 'blackmail',\n",
       " 'blacks',\n",
       " 'blame',\n",
       " 'blamed',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'blend',\n",
       " 'blended',\n",
       " 'blending',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'block-granting',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blocks',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'bluff',\n",
       " 'blumenauer',\n",
       " 'blunt',\n",
       " 'blurted',\n",
       " 'board',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bobbitt',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'boehner',\n",
       " 'boil',\n",
       " 'boiler',\n",
       " 'bolster',\n",
       " 'bomb',\n",
       " 'bombing',\n",
       " 'bombs',\n",
       " 'bond',\n",
       " 'bonded',\n",
       " 'bonding',\n",
       " 'bonds',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'bookkeeper',\n",
       " 'books',\n",
       " 'boon',\n",
       " 'boost',\n",
       " 'booth',\n",
       " 'booties',\n",
       " 'boots',\n",
       " 'boots-on-the-ground',\n",
       " 'border',\n",
       " 'borne',\n",
       " 'borrow',\n",
       " 'borrowing',\n",
       " 'borut',\n",
       " 'boss',\n",
       " 'bosses',\n",
       " 'boston',\n",
       " 'botanical',\n",
       " 'botched',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'boundaries',\n",
       " 'boundless',\n",
       " 'bounties',\n",
       " 'boustany',\n",
       " 'bowen',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'brain',\n",
       " 'brainchild',\n",
       " 'brainwash',\n",
       " 'brake',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'brand',\n",
       " 'brandishing',\n",
       " 'brantley',\n",
       " 'brass',\n",
       " 'brave',\n",
       " 'bravery',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'breaches',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'breeders',\n",
       " 'brentwood',\n",
       " 'bretton',\n",
       " 'brevity',\n",
       " 'brewer',\n",
       " 'bricks',\n",
       " 'bridge',\n",
       " 'brief',\n",
       " 'briefly',\n",
       " 'briefs',\n",
       " 'bright',\n",
       " 'brightest',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brink',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broad',\n",
       " 'broad-based',\n",
       " 'broaden',\n",
       " 'broadening',\n",
       " 'broader',\n",
       " 'broadest',\n",
       " 'broadly',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'brokers',\n",
       " 'brookings',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brown-waite',\n",
       " 'brownfields',\n",
       " 'brunswick-golden',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'bucks',\n",
       " 'bud',\n",
       " 'buddhists',\n",
       " 'budding',\n",
       " 'budget',\n",
       " 'budgeted',\n",
       " 'budgeting',\n",
       " 'budgets',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'buggy',\n",
       " 'build',\n",
       " 'builders',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'builds',\n",
       " 'built',\n",
       " 'built-in',\n",
       " 'bulk',\n",
       " 'bullard',\n",
       " 'bunch',\n",
       " 'burden',\n",
       " 'burdened',\n",
       " 'burdening',\n",
       " 'burdens',\n",
       " 'burdensome',\n",
       " 'bureau',\n",
       " 'bureaucracy',\n",
       " 'bureaucratic',\n",
       " 'bureaucrats',\n",
       " 'burgeoning',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = list(range(0, 10))\n",
    "numbers = list(map(str, numbers))\n",
    "words_list = [i for i in list(TF_pd.columns) if i[0] not in numbers]\n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  392 204 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awfully</th>\n",
       "      <th>bacterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      awfully  bacterial\n",
       "392  0.004132   0.000000\n",
       "204  0.000000   0.009174\n",
       "0    0.000000   0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaos = TF_pd.sort_values(by=['awfully', 'bacterial'], ascending=[0, 0])[['awfully', 'bacterial']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(chaos.index))\n",
    "chaos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  644 661 133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gun</th>\n",
       "      <th>bomb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gun   bomb\n",
       "644  0.001876  0.000\n",
       "661  0.000553  0.000\n",
       "133  0.000000  0.004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_bomb = TF_pd.sort_values(by=['gun', 'bomb'], ascending=[0, 0])[['gun', 'bomb']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(gun_bomb.index))\n",
    "gun_bomb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enough of this garbage, let's cluster\n",
    "\n",
    "Using a **simple counting vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency inverse document frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`CountVectorizer()`:** Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "**`TfidfVectorizer(use_idf=False)`:** Convert a collection of raw documents to a matrix of TF-IDF features. Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "\n",
    "**`TfidfVectorizer(use_idf=True)` (default):** Enable inverse-document-frequency reweighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countingVectorizer = CountVectorizer(tokenizer=simple_tokenizer, stop_words='english')\n",
    "TF_Vectorizer = TfidfVectorizer(use_idf=False, tokenizer=simple_tokenizer, stop_words='english')\n",
    "TF_IDF_Vectorizer = TfidfVectorizer(use_idf=True, tokenizer=simple_tokenizer, stop_words='english')\n",
    "Vectorizer_list = [countingVectorizer, TF_Vectorizer, TF_IDF_Vectorizer]\n",
    "Vectorizer_names = ['', 'simple counting vectorizer', 'term frequency vectorizer', 'term frequency IDF vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] simple counting vectorizer\n",
      "Cluster 0: mr time house s chairman legislation people states elections amendment\n",
      "Cluster 1: head start religious rights civil program discrimination protections amendment programs\n",
      "Cluster 2: mr chairman gentleman amendment time yield speaker s committee house\n",
      "Cluster 3: nbsp amp gt p lt trade -- s united states\n",
      "Cluster 4: rule 11 rules federal h r 420 sanctions judicial litigation\n",
      "Cluster 5: association national restaurant contractors chamber amp electrical commerce chapter american\n",
      "Cluster 6: start head children program amendment mr programs school s chairman\n",
      "Cluster 7: trade china s american cafta church mr u vote people\n",
      "\n",
      "[2] term frequency vectorizer\n",
      "Cluster 0: mr chairman amendment time gentleman s yield horses epa offer\n",
      "Cluster 1: mr yield chairman gentleman minutes 2 1 speaker committee member\n",
      "Cluster 2: start head children program amendment mr chairman programs s religious\n",
      "Cluster 3: time mr balance chairman yield reserve speaker gentleman remaining consume\n",
      "Cluster 4: china trade s speaker mr american legislation vote u time\n",
      "Cluster 5: mr speaker time gentleman house chairman s people committee amendment\n",
      "Cluster 6: mr demand vote recorded chairman speaker nays yeas rollcall pending\n",
      "Cluster 7: yield gentleman mr speaker time texas minutes madam gentlewoman distinguished\n",
      "\n",
      "[3] term frequency IDF vectorizer\n",
      "Cluster 0: demand recorded vote mr speaker chairman yeas nays pending quorum\n",
      "Cluster 1: yield gentleman mr chairman minutes speaker 2 gentlewoman 1 minute\n",
      "Cluster 2: start head children program amendment religious programs school discrimination teachers\n",
      "Cluster 3: claim consent amendment unanimous offer opposition ask chairman oppose mr\n",
      "Cluster 4: mr amendment chairman time gentleman speaker s house people committee\n",
      "Cluster 5: china trade s currency cafta chinese speaker u jobs legislation\n",
      "Cluster 6: resolution immediate direction consideration ask speaker rules committee house previous\n",
      "Cluster 7: balance time chairman reserve mr yield speaker continue reclaiming madam\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for vectorizer in Vectorizer_list:\n",
    "    print(\"\\n[\" + str(count) + \"]\", Vectorizer_names[count])\n",
    "\n",
    "    X = vectorizer.fit_transform(speeches_df['content'])\n",
    "    number_of_clusters = 8\n",
    "    km = KMeans(n_clusters=number_of_clusters)\n",
    "    km.fit(X)\n",
    "    \n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(number_of_clusters):\n",
    "        top_five_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
    "        print(\"Cluster {}: {}\".format(i, ' '.join(top_five_words)))\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which one do you think works the best?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The TF-IDF is definitely the most efficient one, at least in this case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harry Potter time\n",
    "\n",
    "I have a scraped collection of Harry Potter fanfiction at https://github.com/ledeprogram/courses/raw/master/algorithms/data/hp.zip.\n",
    "\n",
    "I want you to read them in, vectorize them and cluster them. Use this process to find out **the two types of Harry Potter fanfiction**. What is your hypothesis?\n",
    "\n",
    "`curl -LO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   149  100   149    0     0    132      0  0:00:01  0:00:01 --:--:--   132\n",
      "100 9226k  100 9226k    0     0  1649k      0  0:00:05  0:00:05 --:--:-- 2129k\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/ledeprogram/courses/raw/master/algorithms/data/hp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hp/10001898.txt', 'hp/10004131.txt', 'hp/10004927.txt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!unzip hp.zip\n",
    "paths_potter = glob.glob('hp/*')\n",
    "paths_potter[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prologue: The MissionDisclaimer: All character...</td>\n",
       "      <td>10001898.txt</td>\n",
       "      <td>hp/10001898.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackDisclaimer: I do not own Harry PotterAuth...</td>\n",
       "      <td>10004131.txt</td>\n",
       "      <td>hp/10004131.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content      filename  \\\n",
       "0  Prologue: The MissionDisclaimer: All character...  10001898.txt   \n",
       "1  BlackDisclaimer: I do not own Harry PotterAuth...  10004131.txt   \n",
       "\n",
       "          pathname  \n",
       "0  hp/10001898.txt  \n",
       "1  hp/10004131.txt  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potter_texts = []\n",
    "for path in paths_potter:\n",
    "    with open(path) as speech_file:\n",
    "        text = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': speech_file.read()\n",
    "        }\n",
    "    potter_texts.append(text)\n",
    "potter_df = pd.DataFrame(potter_texts)\n",
    "potter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: t s lily james sirius\n",
      "Cluster 1: harry hermione t s draco\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prologue: The MissionDisclaimer: All character...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackDisclaimer: I do not own Harry PotterAuth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author's Note: Hey, just so you know, this is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer: I do not own Harry Potter and frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Disclaimer: I don't own any character in the H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DISCLAIMER: I don't own Harry Potter and its c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Katherine Rose-TylerChapter One: the Introduct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am no longer that shy little boy anymore.I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Happy New year! *throws confetti*I've really b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Prologue: The MissionDisclaimer: All character...         0\n",
       "1  BlackDisclaimer: I do not own Harry PotterAuth...         0\n",
       "2  Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...         1\n",
       "3  Author's Note: Hey, just so you know, this is ...         0\n",
       "4  Disclaimer: I do not own Harry Potter and frie...         0\n",
       "5  Disclaimer: I don't own any character in the H...         0\n",
       "6  DISCLAIMER: I don't own Harry Potter and its c...         1\n",
       "7  Katherine Rose-TylerChapter One: the Introduct...         0\n",
       "8  I am no longer that shy little boy anymore.I w...         1\n",
       "9  Happy New year! *throws confetti*I've really b...         0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "vectorizer = TfidfVectorizer(use_idf=True, tokenizer=simple_tokenizer, stop_words='english')\n",
    "X = vectorizer.fit_transform(potter_df['content'])\n",
    "\n",
    "#2\n",
    "number_of_clusters = 2\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "km.fit(X)\n",
    "\n",
    "#3\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))\n",
    "\n",
    "#4\n",
    "results = pd.DataFrame()\n",
    "results['text'] = potter_df['content']\n",
    "results['category'] = km.labels_\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The two types of Harry Potter fanfiction\n",
    "* story of Potter's parents\n",
    "* story of Harry, Hermione and Draco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
