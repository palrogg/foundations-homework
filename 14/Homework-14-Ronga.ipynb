{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all of the things you need to import!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 14 (or so): TF-IDF text analysis and clustering\n",
    "\n",
    "Hooray, we kind of figured out how text analysis works! Some of it is still magic, but at least the **TF** and **IDF** parts make a little sense. Kind of. Somewhat.\n",
    "\n",
    "No, just kidding, we're *professionals* now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Congressional Record\n",
    "\n",
    "The [Congressional Record](https://en.wikipedia.org/wiki/Congressional_Record) is more or less what happened in Congress every single day. Speeches and all that. A good large source of text data, maybe?\n",
    "\n",
    "Let's pretend it's totally secret but we just got it leaked to us in a data dump, and we need to check it out. It was leaked from [this page here](http://www.cs.cornell.edu/home/llee/data/convote.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9607k  100 9607k    0     0  7175k      0  0:00:01  0:00:01 --:--:-- 7180k\n"
     ]
    }
   ],
   "source": [
    "# If you'd like to download it through the command line...\n",
    "!curl -O http://www.cs.cornell.edu/home/llee/data/convote/convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And then extract it through the command line...\n",
    "!tar -zxf convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can explore the files if you'd like, but we're going to get the ones from `convote_v1.1/data_stage_one/development_set/`. It's a bunch of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convote_v1.1/data_stage_one/development_set/052_400011_0327014_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327025_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327044_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_0327046_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set/052_400011_1479036_DON.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob finds files matching a certain filename pattern\n",
    "import glob\n",
    "\n",
    "# Give me all the text files\n",
    "paths = glob.glob('convote_v1.1/data_stage_one/development_set/*')\n",
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So great, we have 702 of them. Now let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr. chairman , i thank the gentlewoman for yie...</td>\n",
       "      <td>052_400011_0327014_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr. chairman , i want to thank my good friend ...</td>\n",
       "      <td>052_400011_0327025_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr. chairman , i rise to make two fundamental ...</td>\n",
       "      <td>052_400011_0327044_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr. chairman , reclaiming my time , let me mak...</td>\n",
       "      <td>052_400011_0327046_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr. chairman , i thank my distinguished collea...</td>\n",
       "      <td>052_400011_1479036_DON.txt</td>\n",
       "      <td>convote_v1.1/data_stage_one/development_set/05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  mr. chairman , i thank the gentlewoman for yie...   \n",
       "1  mr. chairman , i want to thank my good friend ...   \n",
       "2  mr. chairman , i rise to make two fundamental ...   \n",
       "3  mr. chairman , reclaiming my time , let me mak...   \n",
       "4  mr. chairman , i thank my distinguished collea...   \n",
       "\n",
       "                     filename  \\\n",
       "0  052_400011_0327014_DON.txt   \n",
       "1  052_400011_0327025_DON.txt   \n",
       "2  052_400011_0327044_DON.txt   \n",
       "3  052_400011_0327046_DON.txt   \n",
       "4  052_400011_1479036_DON.txt   \n",
       "\n",
       "                                            pathname  \n",
       "0  convote_v1.1/data_stage_one/development_set/05...  \n",
       "1  convote_v1.1/data_stage_one/development_set/05...  \n",
       "2  convote_v1.1/data_stage_one/development_set/05...  \n",
       "3  convote_v1.1/data_stage_one/development_set/05...  \n",
       "4  convote_v1.1/data_stage_one/development_set/05...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = []\n",
    "for path in paths:\n",
    "    with open(path) as speech_file:\n",
    "        speech = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': speech_file.read()\n",
    "        }\n",
    "    speeches.append(speech)\n",
    "speeches_df = pd.DataFrame(speeches)\n",
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we had the `texts` variable. For the homework can just do `speeches_df['content']` to get the same sort of list of stuff.\n",
    "\n",
    "**Take a look at the contents of the first 5 speeches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. chairman , i thank the gentlewoman for yielding me this time . \n",
      "my good colleague from california raised the exact and critical point .  \n",
      "\n",
      "mr. chairman , i want to thank my good friend from california ( mr. rohrabacher ) xz4003430 . \n",
      "i will always remember that day , as we all w \n",
      "\n",
      "mr. chairman , i rise to make two fundamental points before we proceed to vote on this . \n",
      "the two points are these : this resolution does no \n",
      "\n",
      "mr. chairman , reclaiming my time , let me make two final points : one , the majority party must understand this : if you are at a republica \n",
      "\n",
      "mr. chairman , i thank my distinguished colleague , and i appreciate his leadership on this issue . \n",
      "the gentleman from california ( mr. roh \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in speeches_df['content'][:5]:\n",
    "    print(item[:140], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing our analysis\n",
    "\n",
    "Use the `sklearn` package and a plain boring `CountVectorizer` to get a list of all of the tokens used in the speeches. If it won't list them all, that's ok! Make a dataframe with those terms as columns.\n",
    "\n",
    "**Be sure to include English-language stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<702x9106 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 56106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "X = count_vectorizer.fit_transform(speeches_df['content'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00007</th>\n",
       "      <th>018</th>\n",
       "      <th>050</th>\n",
       "      <th>092</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>108th</th>\n",
       "      <th>109th</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>yields</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroing</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zigler</th>\n",
       "      <th>zirkin</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoellick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 9106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  00007  018  050  092  10  100  106  107  108  108th  109th  10th  11  \\\n",
       "0    0      0    0    0    0   0    0    0    0    0      0      0     0   1   \n",
       "1    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "2    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "3    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "4    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "5    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "6    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "7    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "8    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "9    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "\n",
       "   110    ...     yields  york  yorkers  young  younger  youngsters  youth  \\\n",
       "0    0    ...          0     0        0      0        0           0      0   \n",
       "1    0    ...          0     0        0      0        0           0      0   \n",
       "2    0    ...          0     0        0      0        0           0      0   \n",
       "3    0    ...          0     0        0      0        0           0      0   \n",
       "4    0    ...          0     0        0      0        0           0      0   \n",
       "5    0    ...          0     0        0      0        0           0      0   \n",
       "6    0    ...          0     0        0      0        0           0      0   \n",
       "7    0    ...          0     0        0      0        0           0      0   \n",
       "8    0    ...          0     0        0      0        0           0      0   \n",
       "9    0    ...          0     0        0      0        0           0      0   \n",
       "\n",
       "   yuan  zero  zeroing  zeros  zigler  zirkin  zoe  zoellick  \n",
       "0     0     0        0      0       0       0    0         0  \n",
       "1     0     0        0      0       0       0    0         0  \n",
       "2     0     0        0      0       0       0    0         0  \n",
       "3     0     0        0      0       0       0    0         0  \n",
       "4     0     0        0      0       0       0    0         0  \n",
       "5     0     0        0      0       0       0    0         0  \n",
       "6     0     0        0      0       0       0    0         0  \n",
       "7     0     0        0      0       0       0    0         0  \n",
       "8     0     0        0      0       0       0    0         0  \n",
       "9     0     0        0      0       0       0    0         0  \n",
       "\n",
       "[10 rows x 9106 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's **far** too big to even look at. Let's try to get a list of features from a new `CountVectorizer` that only takes the top 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<702x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11088 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
    "X = count_vectorizer.fit_transform(speeches_df['content'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>11</th>\n",
       "      <th>act</th>\n",
       "      <th>allow</th>\n",
       "      <th>amendment</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>amp</th>\n",
       "      <th>association</th>\n",
       "      <th>balance</th>\n",
       "      <th>based</th>\n",
       "      <th>believe</th>\n",
       "      <th>bipartisan</th>\n",
       "      <th>chairman</th>\n",
       "      <th>children</th>\n",
       "      <th>...</th>\n",
       "      <th>teachers</th>\n",
       "      <th>thank</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>trade</th>\n",
       "      <th>united</th>\n",
       "      <th>urge</th>\n",
       "      <th>vote</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  11  act  allow  amendment  america  american  amp  association  \\\n",
       "0    0   1    3      0          0        0         3    0            0   \n",
       "1    0   0    1      1          1        0         0    0            0   \n",
       "2    0   0    0      0          0        0         1    0            0   \n",
       "3    0   0    0      0          0        1         0    0            0   \n",
       "4    0   0    0      0          1        0         0    0            0   \n",
       "\n",
       "   balance  based  believe  bipartisan  chairman  children  ...    teachers  \\\n",
       "0        0      0        1           0         3         0  ...           0   \n",
       "1        1      0        0           0         2         0  ...           0   \n",
       "2        0      0        0           0         2         0  ...           0   \n",
       "3        1      0        0           0         2         0  ...           0   \n",
       "4        0      0        0           0         1         0  ...           0   \n",
       "\n",
       "   thank  think  time  today  trade  united  urge  vote  want  way  work  \\\n",
       "0      1      3     3      2      0       1     0     0     1    1     0   \n",
       "1      1      0     2      2      0       0     0     1     1    3     0   \n",
       "2      0      0     0      0      0       0     0     1     0    0     0   \n",
       "3      0      0     2      0      0       1     0     1     1    1     0   \n",
       "4      1      0     1      0      0       0     0     2     0    0     0   \n",
       "\n",
       "   year  years  yield  \n",
       "0     0      0      1  \n",
       "1     1      0      0  \n",
       "2     0      0      1  \n",
       "3     0      0      0  \n",
       "4     0      0      2  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's push all of that into a dataframe with nicely named columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone seems to start their speeches with \"mr chairman\" - how many speeches are there total, and many don't mention \"chairman\" and how many mention neither \"mr\" nor \"chairman\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a total of 702 speeches, 250 don't mention “chairman” and 76 mention neither “mr” nor “chairman”.\n"
     ]
    }
   ],
   "source": [
    "no_chairman = X_df[X_df['chairman'] == 0]['chairman'].count()\n",
    "no_chairman_no_mr = X_df[(X_df['chairman'] == 0) & (X_df['mr'] == 0)]['chairman'].count()\n",
    "print(\"In a total of\", len(X_df), \"speeches,\", no_chairman, \"don't mention “chairman” and\", no_chairman_no_mr, \"mention neither “mr” nor “chairman”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the index of the speech thank is the most thankful, a.k.a. includes the word 'thank' the most times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of this speech is 577\n"
     ]
    }
   ],
   "source": [
    "print(\"The index of this speech is\", X_df['thank'].idxmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I'm searching for `China` and `trade`, what are the top 3 speeches to read according to the `CountVectoriser`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These three speeches have the indexes  379 399 345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>china</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     china  trade\n",
       "379     29     63\n",
       "399     27      9\n",
       "345     16     11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_trade = X_df.sort_values(by=['china', 'trade'], ascending=[0, 0])[['china', 'trade']].head(3)\n",
    "print(\"These three speeches have the indexes \", *list(china_trade.index))\n",
    "china_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if I'm using a `TfidfVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  345 340 315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>china</th>\n",
       "      <th>trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.078818</td>\n",
       "      <td>0.054187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.008197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.035000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        china     trade\n",
       "345  0.078818  0.054187\n",
       "340  0.057377  0.008197\n",
       "315  0.055000  0.035000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    return words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=simple_tokenizer, use_idf=False, norm='l1')\n",
    "X = tfidf_vectorizer.fit_transform(speeches_df['content'])\n",
    "TF_pd = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "china_trade = TF_pd.sort_values(by=['china', 'trade'], ascending=[0, 0])[['china', 'trade']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(china_trade.index))\n",
    "china_trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the content of the speeches?** Here's a way to get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convote_v1.1/data_stage_one/development_set/052_400011_0327014_DON.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 0 is the first speech, which was the first one imported.\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. chairman , i thank the gentlewoman for yielding me this time . \r\n",
      "my good colleague from california raised the exact and critical point . \r\n",
      "the question is , what happens during those 45 days ? \r\n",
      "we will need to support elections . \r\n",
      "there is not a single member of this house who has not supported some form of general election , a special election , to replace the members at some point . \r\n",
      "but during that 45 days , what happens ? \r\n",
      "the chair of the constitution subcommittee says this is what happens : martial law . \r\n",
      "we do not know who would fill the vacancy of the presidency , but we do know that the succession act most likely suggests it would be an unelected person . \r\n",
      "the sponsors of the bill before us today insist , and i think rightfully so , on the importance of elections . \r\n",
      "but to then say that during a 45-day period we would have none of the checks and balances so fundamental to our constitution , none of the separation of powers , and that the presidency would be filled by an unelected member of the cabinet who not a single member of this country , not a single citizen , voted to fill that position , and that that person would have no checks and balances from congress for a period of 45 days i find extraordinary . \r\n",
      "i find it inconsistent . \r\n",
      "i find it illogical , and , frankly , i find it dangerous . \r\n",
      "the gentleman from wisconsin refused earlier to yield time , but i was going to ask him , if virginia has those elections in a shorter time period , they should be commended for that . \r\n",
      "so now we have a situation in the congress where the virginia delegation has sent their members here , but many other states do not have members here . \r\n",
      "do they at that point elect a speaker of the house in the absence of other members ? \r\n",
      "and then three more states elect their representatives , temporary replacements , or full replacements at that point . \r\n",
      "they come in . \r\n",
      "do they elect a new speaker ? \r\n",
      "and if that happens , who becomes the president under the succession act ? \r\n",
      "this bill does not address that question . \r\n",
      "this bill responds to real threats with fantasies . \r\n",
      "it responds with the fantasy , first of all , that a lot of people will still survive ; but we have no guarantee of that . \r\n",
      "it responds with the fantasy that those who do survive will do the right thing . \r\n",
      "we are here having this debate , we have debates every day , because people differ on what the right thing is to do . \r\n",
      "i have been in very traumatic situations with people in severe car wrecks and mountain climbing accidents . \r\n",
      "my experience has not been that crisis imbues universal sagacity and fairness . \r\n",
      "it has not been that . \r\n",
      "people respond in extraordinary ways , and we must preserve an institution that has the deliberative body and the checks and balances to meet those challenges . \r\n",
      "many of our states are going increasingly to mail-in ballots . \r\n",
      "we in this body were effectively disabled by an anthrax attack not long after september 11 . \r\n",
      "i would ask my dear friends , will you conduct this election in 45 days if there is anthrax in the mail and still preserve the franchise of the american people ? \r\n",
      "how will you do that ? \r\n",
      "you have no answer to that question . \r\n",
      "i find it extraordinary , frankly , that while saying you do not want to amend the constitution , we began this very congress by amending the constitution through the rule , by undermining the principle that a quorum is 50 percent of the body and instead saying it is however many people survive . \r\n",
      "and if that rule applies , who will designate it , who will implement it ? \r\n",
      "the speaker , or the speaker 's designee ? \r\n",
      "again , not an elected person , as you say is so critical and i believe is critical , but a temporary appointee , frankly , who not a single other member of this body knows who they are . \r\n",
      "so we not only have an unelected person , we have an unknown person who will convene this body , and who , by the way , could conceivably convene it for their own election to then become the president of the united states under the succession act . \r\n",
      "you have refused steadfastly to debate this real issue broadly . \r\n",
      "you had a mock debate in the committee on the judiciary in which the distinguished chairman presented my bill without allowing me the courtesy or dignity to defend it myself . \r\n",
      "and on that , you proudly say you defend democracy . \r\n",
      "sir , i think you dissemble in that regard . \r\n",
      "here is the fundamental question for us , my friends , and it is this : the american people are watching television and an announcement comes on and says the congress has been destroyed in a nuclear attack , the president and vice president are killed and the supreme court is dead and thousands of our citizens in this town are . \r\n",
      "what happens next ? \r\n",
      "under your bill , 45 days of chaos . \r\n",
      "apparently , according to the committee on the judiciary subcommittee on the constitution chairman , 45 days of marshal law , rule of this country by an unelected president with no checks and balances . \r\n",
      "or an alternative , an alternative which says quite simply that the people have entrusted the representatives they send here to make profound decisions , war , taxation , a host of other things , and those representatives would have the power under the bill of the gentleman from california ( mr. rohrabacher ) xz4003430 bill or mine to designate temporary successors , temporary , only until we can have a real election . \r\n",
      "the american people , in one scenario , are told we do not know who is going to run the country , we have no representatives ; where in another you will have temporary representatives carrying your interests to this great body while we deliberate and have real elections . \r\n",
      "that is the choice . \r\n",
      "you are making the wrong choice today if you think you have solved this problem . \r\n"
     ]
    }
   ],
   "source": [
    "# Pass that into 'cat' using { } which lets you put variables in shell commands\n",
    "# that way you can pass the path to cat\n",
    "!cat {paths[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now search for something else!** Another two terms that might show up. `elections` and `chaos`? Whatever you thnik might be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaron|aba|abandon|abandoned|abandoning|abcs|abet|abhorrent|abide|abides|abiding|abilities|ability|able|ably|abolish|abraham|abridgement|abroad|abrogation|absence|absent|absentee|absolutely|absolve|absorb|absurd|abundance|abundant|abuse|abused|abuses|abusing|abusive|abysmal|academic|academically|academics|academy|accede|accelerated|accept|acceptable|acceptance|accepted|accepting|accepts|access|accessible|accessing|accession|accessories|accident|accidents|acclaimed|accommodate|accommodated|accommodating|accompanies|accompanying|accomplish|accomplished|accomplishes|accomplishment|accordance|according|accordingly|account|accountability|accountable|accountant|accounting|accounts|accumulated|accumulation|accurate|accurately|accusations|accused|accustom|achieve|achieved|achievement|achievements|achieving|acknowledge|acknowledged|acknowledges|aclu|acquainted|acquire|acquired|acquisition|acquisitions|acre\n"
     ]
    }
   ],
   "source": [
    "numbers = list(range(0, 10))\n",
    "numbers = list(map(str, numbers))\n",
    "words_list = [i for i in list(TF_pd.columns) if i[0] not in numbers]\n",
    "print(*words_list[5:100], sep='|') # to get some ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  392 204 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awfully</th>\n",
       "      <th>bacterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      awfully  bacterial\n",
       "392  0.004132   0.000000\n",
       "204  0.000000   0.009174\n",
       "0    0.000000   0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaos = TF_pd.sort_values(by=['awfully', 'bacterial'], ascending=[0, 0])[['awfully', 'bacterial']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(chaos.index))\n",
    "chaos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three top speeches have the indexes  644 661 133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gun</th>\n",
       "      <th>bomb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          gun   bomb\n",
       "644  0.001876  0.000\n",
       "661  0.000553  0.000\n",
       "133  0.000000  0.004"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_bomb = TF_pd.sort_values(by=['gun', 'bomb'], ascending=[0, 0])[['gun', 'bomb']].head(3)\n",
    "print(\"The three top speeches have the indexes \", *list(gun_bomb.index))\n",
    "gun_bomb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enough of this garbage, let's cluster\n",
    "\n",
    "Using a **simple counting vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency inverse document frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`CountVectorizer()`:** Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "**`TfidfVectorizer(use_idf=False)`:** Convert a collection of raw documents to a matrix of TF-IDF features. Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "\n",
    "**`TfidfVectorizer(use_idf=True)` (default):** Enable inverse-document-frequency reweighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countingVectorizer = CountVectorizer(tokenizer=simple_tokenizer, stop_words='english')\n",
    "TF_Vectorizer = TfidfVectorizer(use_idf=False, tokenizer=simple_tokenizer, stop_words='english')\n",
    "TF_IDF_Vectorizer = TfidfVectorizer(use_idf=True, tokenizer=simple_tokenizer, stop_words='english')\n",
    "Vectorizer_list = [countingVectorizer, TF_Vectorizer, TF_IDF_Vectorizer]\n",
    "Vectorizer_names = ['', 'simple counting vectorizer', 'term frequency vectorizer', 'term frequency IDF vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] simple counting vectorizer\n",
      "Cluster 0: mr s time house trade people amendment chairman states china\n",
      "Cluster 1: head start religious rights civil program discrimination protections amendment programs\n",
      "Cluster 2: nbsp amp gt p lt trade -- s united states\n",
      "Cluster 3: mr chairman gentleman time amendment yield speaker s committee head\n",
      "Cluster 4: rule 11 rules federal h r 420 sanctions judicial litigation\n",
      "Cluster 5: association national restaurant contractors chamber amp electrical commerce chapter american\n",
      "Cluster 6: start head children program amendment mr programs school s chairman\n",
      "Cluster 7: church s financial embezzlement -- churches says checks 000 funds\n",
      "\n",
      "[2] term frequency vectorizer\n",
      "Cluster 0: start head children program amendment mr chairman programs s religious\n",
      "Cluster 1: mr chairman amendment gentleman time s house people committee congress\n",
      "Cluster 2: chairman mr time balance yield amendment reserve vote gentleman demand\n",
      "Cluster 3: china trade s speaker mr legislation american vote u time\n",
      "Cluster 4: speaker mr time yield gentleman balance committee vote reserve demand\n",
      "Cluster 5: yield gentleman texas wisconsin illinois gentlewoman ohio michigan california north\n",
      "Cluster 6: frivolous lawsuits rule state legislation mr court s federal 11\n",
      "Cluster 7: mr yield gentleman chairman minutes 2 speaker 1 member minute\n",
      "\n",
      "[3] term frequency IDF vectorizer\n",
      "Cluster 0: election elections house days time people special states amendment mr\n",
      "Cluster 1: yield gentleman mr chairman texas illinois wisconsin speaker michigan ohio\n",
      "Cluster 2: demand recorded vote mr speaker chairman yeas nays pending quorum\n",
      "Cluster 3: china trade s currency speaker cafta chinese u wto jobs\n",
      "Cluster 4: mr yield minutes gentleman chairman 2 speaker 1 gentlewoman minute\n",
      "Cluster 5: mr amendment chairman time speaker gentleman s offer committee ask\n",
      "Cluster 6: start head children program amendment religious programs school discrimination services\n",
      "Cluster 7: balance time chairman mr yield reserve speaker continue reclaiming consume\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for vectorizer in Vectorizer_list:\n",
    "    print(\"\\n[\" + str(count) + \"]\", Vectorizer_names[count])\n",
    "\n",
    "    X = vectorizer.fit_transform(speeches_df['content'])\n",
    "    number_of_clusters = 8\n",
    "    km = KMeans(n_clusters=number_of_clusters)\n",
    "    km.fit(X)\n",
    "    \n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(number_of_clusters):\n",
    "        top_five_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
    "        print(\"Cluster {}: {}\".format(i, ' '.join(top_five_words)))\n",
    "        \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which one do you think works the best?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The TF-IDF is definitely the most efficient one, at least in this case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harry Potter time\n",
    "\n",
    "I have a scraped collection of Harry Potter fanfiction at https://github.com/ledeprogram/courses/raw/master/algorithms/data/hp.zip.\n",
    "\n",
    "I want you to read them in, vectorize them and cluster them. Use this process to find out **the two types of Harry Potter fanfiction**. What is your hypothesis?\n",
    "\n",
    "`curl -LO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   149  100   149    0     0    119      0  0:00:01  0:00:01 --:--:--   119\n",
      "100 9226k  100 9226k    0     0  1809k      0  0:00:05  0:00:05 --:--:-- 3014k\n"
     ]
    }
   ],
   "source": [
    "!curl -LO https://github.com/ledeprogram/courses/raw/master/algorithms/data/hp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hp/10001898.txt', 'hp/10004131.txt', 'hp/10004927.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!unzip hp.zip\n",
    "paths_potter = glob.glob('hp/*')\n",
    "paths_potter[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prologue: The MissionDisclaimer: All character...</td>\n",
       "      <td>10001898.txt</td>\n",
       "      <td>hp/10001898.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackDisclaimer: I do not own Harry PotterAuth...</td>\n",
       "      <td>10004131.txt</td>\n",
       "      <td>hp/10004131.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content      filename  \\\n",
       "0  Prologue: The MissionDisclaimer: All character...  10001898.txt   \n",
       "1  BlackDisclaimer: I do not own Harry PotterAuth...  10004131.txt   \n",
       "\n",
       "          pathname  \n",
       "0  hp/10001898.txt  \n",
       "1  hp/10004131.txt  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potter_texts = []\n",
    "for path in paths_potter:\n",
    "    with open(path) as speech_file:\n",
    "        text = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': speech_file.read()\n",
    "        }\n",
    "    potter_texts.append(text)\n",
    "potter_df = pd.DataFrame(potter_texts)\n",
    "potter_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: t s lily james sirius\n",
      "Cluster 1: harry hermione t s draco\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prologue: The MissionDisclaimer: All character...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackDisclaimer: I do not own Harry PotterAuth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author's Note: Hey, just so you know, this is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer: I do not own Harry Potter and frie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Disclaimer: I don't own any character in the H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DISCLAIMER: I don't own Harry Potter and its c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Katherine Rose-TylerChapter One: the Introduct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I am no longer that shy little boy anymore.I w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Happy New year! *throws confetti*I've really b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  category\n",
       "0  Prologue: The MissionDisclaimer: All character...         0\n",
       "1  BlackDisclaimer: I do not own Harry PotterAuth...         0\n",
       "2  Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...         1\n",
       "3  Author's Note: Hey, just so you know, this is ...         0\n",
       "4  Disclaimer: I do not own Harry Potter and frie...         0\n",
       "5  Disclaimer: I don't own any character in the H...         0\n",
       "6  DISCLAIMER: I don't own Harry Potter and its c...         1\n",
       "7  Katherine Rose-TylerChapter One: the Introduct...         0\n",
       "8  I am no longer that shy little boy anymore.I w...         1\n",
       "9  Happy New year! *throws confetti*I've really b...         0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "vectorizer = TfidfVectorizer(use_idf=True, tokenizer=simple_tokenizer, stop_words='english')\n",
    "X = vectorizer.fit_transform(potter_df['content'])\n",
    "\n",
    "#2\n",
    "number_of_clusters = 2\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "km.fit(X)\n",
    "\n",
    "#3\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))\n",
    "\n",
    "#4\n",
    "results = pd.DataFrame()\n",
    "results['text'] = potter_df['content']\n",
    "results['category'] = km.labels_\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The two types of Harry Potter fanfiction\n",
    "* story of Potter's parents\n",
    "* story of Harry, Hermione and Draco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
